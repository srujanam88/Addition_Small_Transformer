{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install Libraries"
      ],
      "metadata": {
        "id": "XKSfs6TyAS4g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrO_TP8m_1fh",
        "outputId": "7ce43038-4ddc-44cd-b2ae-563e24bf17f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "\n",
        "k = 4. # number of digits - 1000 to 9999\n",
        "num_samples = 75000\n",
        "\n",
        "frac_train = 0.6\n",
        "frac_val = 0.2"
      ],
      "metadata": {
        "id": "vvSV0pzv90g4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Task\n",
        "\n",
        "*   Define input and output (\"a + b =\" and \"c\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nQMB7PenAYG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_dataset(num_samples):\n",
        "\n",
        "    dataset = set()\n",
        "\n",
        "    while len(dataset) < num_samples:\n",
        "      a = random.randint(1000, 9999)\n",
        "      b = random.randint(1000, 9999)\n",
        "\n",
        "      c = a + b  #Addition\n",
        "\n",
        "      input_str = f\"{a} + {b} =\"\n",
        "      output_str = str(c)\n",
        "\n",
        "      dataset.add((input_str, output_str))\n",
        "\n",
        "    return list(dataset)\n",
        "\n",
        "dataset = generate_dataset(num_samples)\n",
        "print(f\"Length of dataset: {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayqXKaf5AjAv",
        "outputId": "90d91d59-aed4-41a6-a843-9779b800bd8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset: 75000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, val, test split\n",
        "random.shuffle(dataset)\n",
        "\n",
        "train_end = int(num_samples * frac_train)\n",
        "val_end = train_end + int(num_samples * frac_val)\n",
        "\n",
        "train_data = dataset[:train_end]\n",
        "val_data = dataset[train_end:val_end]\n",
        "test_data = dataset[val_end:]\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93cnFcQkHVYL",
        "outputId": "b4435ae6-6157-40ae-c0f2-7cefb29dc392"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45000\n",
            "15000\n",
            "15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1EL5rjzJbVU",
        "outputId": "b2af1046-ce2e-4f7c-80c2-1907e7cabe91"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('4113 + 3092 =', '7205'), ('7051 + 7153 =', '14204'), ('2538 + 6880 =', '9418'), ('4483 + 2037 =', '6520'), ('5896 + 8526 =', '14422')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training\n",
        "\n",
        "\n",
        "*   Character Tokenizer\n",
        "*   Transformer Model\n",
        "*   Training Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "5vKhRqvjZHbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IqZhq4n4KxVc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "class CharacterTokenizer:\n",
        "    \"\"\"Character-level tokenizer for addition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chars = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '+', '=']\n",
        "        self.PAD_TOKEN = '<PAD>'\n",
        "\n",
        "        self.vocab = [self.PAD_TOKEN] + self.chars\n",
        "        self.char_to_idx = {char: idx for idx, char in enumerate(self.vocab)}\n",
        "        self.idx_to_char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.pad_idx = self.char_to_idx[self.PAD_TOKEN]\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Convert text to token indices\"\"\"\n",
        "        return [self.char_to_idx[char] for char in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        \"\"\"Convert token indices back to text\"\"\"\n",
        "        chars = [self.idx_to_char[idx] for idx in indices\n",
        "                 if idx != self.pad_idx]\n",
        "        return ''.join(chars)\n",
        "\n",
        "# Dataset preparation - convert to tokens\n",
        "class AdditionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=32, ignore_index=-100):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_str, output_str = self.data[idx]\n",
        "\n",
        "        full_sequence = input_str + \" \" + output_str  # \"2506 + 7036 = 9542\"\n",
        "        prompt = input_str + \" \"                       # \"2506 + 7036 = \"\n",
        "\n",
        "        full_tokens = self.tokenizer.encode(full_sequence)\n",
        "        prompt_len = len(self.tokenizer.encode(prompt))\n",
        "\n",
        "        # Pad if needed\n",
        "        if len(full_tokens) < self.max_length:\n",
        "            full_tokens = full_tokens + [self.tokenizer.pad_idx] * (self.max_length - len(full_tokens))\n",
        "        else:\n",
        "            full_tokens = full_tokens[:self.max_length]\n",
        "\n",
        "        # Shift for autoregressive\n",
        "        input_ids = torch.tensor(full_tokens[:-1], dtype=torch.long)\n",
        "        labels = torch.tensor(full_tokens[1:], dtype=torch.long)\n",
        "\n",
        "        # Mask prompt portion\n",
        "        # In labels, the prompt occupies positions 0 to (prompt_len - 2) because of the shift\n",
        "        labels[:prompt_len - 1] = self.ignore_index\n",
        "\n",
        "        # Mask padding\n",
        "        labels[labels == self.tokenizer.pad_idx] = self.ignore_index\n",
        "\n",
        "        return input_ids, labels"
      ],
      "metadata": {
        "id": "xIq1ZkN2ZJ2k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=6,\n",
        "                 dim_feedforward=512, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        src = self.dropout(src)\n",
        "\n",
        "        output = self.transformer(src, src_key_padding_mask=src_mask)\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "al8cGDQUaGUr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Functions\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device, grad_clip=1.0):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct_chars = 0\n",
        "    total_chars = 0\n",
        "    total_correct_seqs = 0\n",
        "    total_seqs = 0\n",
        "\n",
        "    for batch_idx, (input_ids, target_ids) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        input_ids = input_ids.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids)\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), target_ids.reshape(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Character accuracy\n",
        "        predictions = logits.argmax(dim=-1)\n",
        "        mask = target_ids != -100\n",
        "        correct = (predictions == target_ids) & mask\n",
        "        total_correct_chars += correct.sum().item()\n",
        "        total_chars += mask.sum().item()\n",
        "\n",
        "        # Sequence accuracy\n",
        "        for pred_seq, label_seq in zip(predictions, target_ids):\n",
        "            output_mask = label_seq != -100\n",
        "            if output_mask.sum() > 0:\n",
        "                if torch.equal(pred_seq[output_mask], label_seq[output_mask]):\n",
        "                    total_correct_seqs += 1\n",
        "                total_seqs += 1\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    char_accuracy = total_correct_chars / total_chars\n",
        "    seq_accuracy = total_correct_seqs / total_seqs if total_seqs > 0 else 0.0\n",
        "\n",
        "    return avg_loss, char_accuracy, seq_accuracy\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, criterion, tokenizer, device):\n",
        "    \"\"\"Evaluate on validation/test set\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct_chars = 0\n",
        "    total_chars = 0\n",
        "    total_correct_sequences = 0\n",
        "    total_sequences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(input_ids)\n",
        "\n",
        "            loss = criterion(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                labels.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "\n",
        "            # Character accuracy (only on non-masked tokens(output))\n",
        "            mask = labels != criterion.ignore_index\n",
        "            correct_chars = (predictions == labels) & mask\n",
        "            total_correct_chars += correct_chars.sum().item()\n",
        "            total_chars += mask.sum().item()\n",
        "\n",
        "            # Sequence accuracy\n",
        "            for pred_seq, label_seq in zip(predictions, labels):\n",
        "                # Extract only output tokens (non-masked)\n",
        "                output_mask = label_seq != criterion.ignore_index\n",
        "                pred_output = pred_seq[output_mask]\n",
        "                label_output = label_seq[output_mask]\n",
        "\n",
        "                if torch.equal(pred_output, label_output):\n",
        "                    total_correct_sequences += 1\n",
        "                total_sequences += 1\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    char_accuracy = total_correct_chars / total_chars\n",
        "    seq_accuracy = total_correct_sequences / total_sequences\n",
        "\n",
        "    return avg_loss, char_accuracy, seq_accuracy\n"
      ],
      "metadata": {
        "id": "_dJURCAYZbwI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, scheduler, criterion,\n",
        "                tokenizer, device, num_epochs, save_path='best_model.pt'):\n",
        "    \"\"\"Main training loop with early stopping\"\"\"\n",
        "\n",
        "    best_train_seq_acc = 0.0\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_seq_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"EPOCH {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        train_loss, train_char_acc, train_seq_acc = train_epoch(\n",
        "            model, train_loader, optimizer, criterion, device\n",
        "        )\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_char_acc, val_seq_acc = evaluate(\n",
        "            model, val_loader, criterion, tokenizer, device\n",
        "        )\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_seq_acc'].append(train_seq_acc)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Train: Loss={train_loss:.4f}, SeqAcc={train_seq_acc:.4f}\")\n",
        "        print(f\"Val:   Loss={val_loss:.4f}, SeqAcc={val_seq_acc:.4f}\")\n",
        "\n",
        "        # Save\n",
        "        if train_seq_acc >= best_train_seq_acc and val_seq_acc >= 0.99:\n",
        "            best_train_seq_acc = train_seq_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'train_seq_acc': train_seq_acc,\n",
        "                'val_seq_acc': val_seq_acc,\n",
        "            }, save_path)\n",
        "            print(f\"Saved (TrainSeqAcc: {train_seq_acc:.4f})\")\n",
        "\n",
        "        # Stop if train is perfect\n",
        "        if train_seq_acc >= 1.0:\n",
        "            print(f\"Reached 100% training accuracy at epoch {epoch+1}!\")\n",
        "            break\n",
        "\n",
        "    # Load best model\n",
        "    checkpoint = torch.load(save_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"\\n model saved at: TrainSeq={checkpoint['train_seq_acc']:.4f}, ValSeq={checkpoint['val_seq_acc']:.4f}\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "bXDmMSkcunuM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = CharacterTokenizer()\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = AdditionDataset(train_data, tokenizer, max_length=32)\n",
        "val_dataset = AdditionDataset(val_data, tokenizer, max_length=32)\n",
        "test_dataset = AdditionDataset(test_data, tokenizer, max_length=32)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize model\n",
        "model = TransformerModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    d_model=128,\n",
        "    nhead=4,\n",
        "    num_layers=6,\n",
        "    dim_feedforward=512,\n",
        "    dropout=0.1,\n",
        "    max_len=32\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "# Learning rate scheduler\n",
        "def lr_lambda(step):\n",
        "    warmup_steps = 1000\n",
        "    if step < warmup_steps:\n",
        "        return step / warmup_steps\n",
        "    return 0.5 ** ((step - warmup_steps) / 5000)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "# Train!\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    criterion=criterion,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    num_epochs=30,\n",
        "    save_path='best_model.pt'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgID8cnduSzZ",
        "outputId": "4c7f3024-6fbc-4a4b-9ca4-1b57d629a60a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Vocabulary size: 14\n",
            "Total parameters: 1,193,230\n",
            "EPOCH 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.40it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 30.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.9396, SeqAcc=0.4935\n",
            "Val:   Loss=0.0025, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.4935)\n",
            "EPOCH 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.50it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0095, SeqAcc=0.9927\n",
            "Val:   Loss=0.0007, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9927)\n",
            "EPOCH 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.19it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0088, SeqAcc=0.9913\n",
            "Val:   Loss=0.0011, SeqAcc=0.9983\n",
            "EPOCH 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.17it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0060, SeqAcc=0.9939\n",
            "Val:   Loss=0.0002, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9939)\n",
            "EPOCH 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.23it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0022, SeqAcc=0.9981\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9981)\n",
            "EPOCH 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.25it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0031, SeqAcc=0.9970\n",
            "Val:   Loss=0.0003, SeqAcc=0.9997\n",
            "EPOCH 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.76it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0033, SeqAcc=0.9971\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "EPOCH 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.80it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0038, SeqAcc=0.9962\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "EPOCH 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.82it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 33.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0021, SeqAcc=0.9982\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9982)\n",
            "EPOCH 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 17.91it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0032, SeqAcc=0.9972\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "EPOCH 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.02it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0015, SeqAcc=0.9984\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9984)\n",
            "EPOCH 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.05it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0018, SeqAcc=0.9987\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9987)\n",
            "EPOCH 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.01it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0014, SeqAcc=0.9988\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9988)\n",
            "EPOCH 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.02it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0022, SeqAcc=0.9980\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.43it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 29.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0010, SeqAcc=0.9992\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9992)\n",
            "EPOCH 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.56it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 27.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0009, SeqAcc=0.9995\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9995)\n",
            "EPOCH 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.51it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0019, SeqAcc=0.9986\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "EPOCH 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.54it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 32.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0014, SeqAcc=0.9989\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.15it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0007, SeqAcc=0.9996\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9996)\n",
            "EPOCH 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 17.87it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0010, SeqAcc=0.9994\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.03it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0004, SeqAcc=0.9997\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9997)\n",
            "EPOCH 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.01it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0008, SeqAcc=0.9994\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.18it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0023, SeqAcc=0.9982\n",
            "Val:   Loss=0.0001, SeqAcc=1.0000\n",
            "EPOCH 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.48it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 30.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0004, SeqAcc=0.9997\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9997)\n",
            "EPOCH 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.54it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0002, SeqAcc=0.9999\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9999)\n",
            "EPOCH 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:18<00:00, 18.54it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:04<00:00, 28.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0004, SeqAcc=0.9996\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.50it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 31.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0004, SeqAcc=0.9997\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 18.22it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 33.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0002, SeqAcc=0.9999\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "Saved (TrainSeqAcc: 0.9999)\n",
            "EPOCH 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 17.99it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0006, SeqAcc=0.9995\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "EPOCH 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 352/352 [00:19<00:00, 17.93it/s]\n",
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Loss=0.0005, SeqAcc=0.9996\n",
            "Val:   Loss=0.0000, SeqAcc=1.0000\n",
            "\n",
            " model saved at: TrainSeq=0.9999, ValSeq=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Training Loss\n",
        "ax1.plot(history['train_loss'], marker='o', linewidth=2, markersize=4)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Training Sequence Accuracy\n",
        "ax2.plot(history['train_seq_acc'], marker='o', linewidth=2, markersize=4, color='green')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Sequence Accuracy')\n",
        "ax2.set_title('Training Sequence Accuracy')\n",
        "ax2.set_ylim([0, 1.05])\n",
        "ax2.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='100%')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9NCwSX8noX35",
        "outputId": "f02105a2-7c4c-4191-ea24-5fc7a164b0e0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sample_predictions(model, dataset, tokenizer, device, num_samples=5):\n",
        "    \"\"\"Print sample predictions to see how model is doing\"\"\"\n",
        "    model.eval()\n",
        "    print(\"SAMPLE PREDICTIONS\")\n",
        "\n",
        "    indices = torch.randperm(len(dataset))[:num_samples]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in indices:\n",
        "            input_ids, target_ids = dataset[idx]\n",
        "            input_ids_tensor = input_ids.unsqueeze(0).to(device)\n",
        "\n",
        "            logits = model(input_ids_tensor)\n",
        "            predictions = logits.argmax(dim=-1).squeeze(0)\n",
        "\n",
        "            # Create mask for non-ignored tokens\n",
        "            mask = target_ids != -100\n",
        "\n",
        "            # Get the actual original data to show the prompt\n",
        "            original_input, original_output = dataset.data[idx]\n",
        "\n",
        "            # Extract target tokens (only non-masked positions)\n",
        "            target_tokens = target_ids[mask].cpu().tolist()\n",
        "\n",
        "            # Extract predicted tokens (same positions)\n",
        "            pred_tokens = predictions[mask].cpu().tolist()\n",
        "\n",
        "            # Decode\n",
        "            target_text = tokenizer.decode(target_tokens)\n",
        "            pred_text = tokenizer.decode(pred_tokens)\n",
        "\n",
        "            # Display\n",
        "            print(f\"Problem:     {original_input}\")\n",
        "            print(f\"Expected:    {original_output}\")\n",
        "            print(f\"Target:      {target_text}\")\n",
        "            print(f\"Predicted:   {pred_text}\")"
      ],
      "metadata": {
        "id": "lUKadRnyh8Nt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('best_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"IN-DISTRIBUTION TEST SET EVALUATION\")\n",
        "\n",
        "test_dataset = AdditionDataset(test_data, tokenizer, max_length=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "# Evaluate on test set\n",
        "test_loss, test_char_acc, test_seq_acc = evaluate(\n",
        "    model, test_loader, criterion, tokenizer, device\n",
        ")\n",
        "print(len(test_loader))\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  Loss: {test_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {test_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {test_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, test_dataset, tokenizer, device, num_samples=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SunZEo0uajn",
        "outputId": "897b5ce6-7f86-465b-c9bf-121fc46b66b1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN-DISTRIBUTION TEST SET EVALUATION\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 118/118 [00:03<00:00, 33.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118\n",
            "\n",
            "Test Results:\n",
            "  Loss: 0.0000\n",
            "  Character Accuracy: 1.0000\n",
            "  Sequence Accuracy: 1.0000\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     3145 + 3765 =\n",
            "Expected:    6910\n",
            "Target:      6910\n",
            "Predicted:   6910\n",
            "Problem:     9994 + 3202 =\n",
            "Expected:    13196\n",
            "Target:      13196\n",
            "Predicted:   13196\n",
            "Problem:     9620 + 4787 =\n",
            "Expected:    14407\n",
            "Target:      14407\n",
            "Predicted:   14407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_length_generalization_data(k, num_samples=1000):\n",
        "    \"\"\"Generate k-digit addition problems\"\"\"\n",
        "    data = []\n",
        "    min_val = 10 ** (k - 1)\n",
        "    max_val = 10 ** k - 1\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        a = random.randint(min_val, max_val)\n",
        "        b = random.randint(min_val, max_val)\n",
        "        c = a + b\n",
        "        input_str = f\"{a} + {b} =\"\n",
        "        output_str = str(c)\n",
        "        data.append((input_str, output_str))\n",
        "\n",
        "    return data\n",
        "\n",
        "# Test on 5-digit numbers (k+1)\n",
        "print(\"LENGTH GENERALIZATION: 5-DIGIT NUMBERS (k+1)\")\n",
        "\n",
        "k5_data = generate_length_generalization_data(k=5, num_samples=1000)\n",
        "k5_dataset = AdditionDataset(k5_data, tokenizer, max_length=32)\n",
        "k5_loader = DataLoader(k5_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "k5_loss, k5_char_acc, k5_seq_acc = evaluate(\n",
        "    model, k5_loader, criterion, tokenizer, device\n",
        ")\n",
        "\n",
        "print(f\"\\n5-Digit Results:\")\n",
        "print(f\"  Loss: {k5_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {k5_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {k5_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, k5_dataset, tokenizer, device, num_samples=3)\n",
        "\n",
        "# Test on 6-digit numbers (k+2)\n",
        "print(\"LENGTH GENERALIZATION: 6-DIGIT NUMBERS (k+2)\")\n",
        "\n",
        "k6_data = generate_length_generalization_data(k=6, num_samples=1000)\n",
        "k6_dataset = AdditionDataset(k6_data, tokenizer, max_length=32)\n",
        "k6_loader = DataLoader(k6_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "k6_loss, k6_char_acc, k6_seq_acc = evaluate(\n",
        "    model, k6_loader, criterion, tokenizer, device\n",
        ")\n",
        "\n",
        "print(f\"\\n6-Digit Results:\")\n",
        "print(f\"  Loss: {k6_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {k6_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {k6_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, k6_dataset, tokenizer, device, num_samples=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-HzXpGVejf8",
        "outputId": "aa1086bb-304b-4d29-9f19-97a96bfa09b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LENGTH GENERALIZATION: 5-DIGIT NUMBERS (k+1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5-Digit Results:\n",
            "  Loss: 4.3657\n",
            "  Character Accuracy: 0.5615\n",
            "  Sequence Accuracy: 0.0090\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     53604 + 85080 =\n",
            "Expected:    138684\n",
            "Target:      138684\n",
            "Predicted:   038884\n",
            "Problem:     72223 + 57205 =\n",
            "Expected:    129428\n",
            "Target:      129428\n",
            "Predicted:   224888\n",
            "Problem:     28291 + 55639 =\n",
            "Expected:    83930\n",
            "Target:      83930\n",
            "Predicted:   33900\n",
            "LENGTH GENERALIZATION: 6-DIGIT NUMBERS (k+2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 22.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6-Digit Results:\n",
            "  Loss: 7.7325\n",
            "  Character Accuracy: 0.2124\n",
            "  Sequence Accuracy: 0.0000\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     140366 + 539800 =\n",
            "Expected:    680166\n",
            "Target:      680166\n",
            "Predicted:   080000\n",
            "Problem:     105360 + 694902 =\n",
            "Expected:    800262\n",
            "Target:      800262\n",
            "Predicted:   002222\n",
            "Problem:     262996 + 628247 =\n",
            "Expected:    891243\n",
            "Target:      891243\n",
            "Predicted:   494447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I just checked if 4-digit addition is working if first digit is 0 -> learnt well\n",
        "def generate_length_generalization_data(k, num_samples=1000):\n",
        "    \"\"\"Generate k-digit addition problems\"\"\"\n",
        "    data = []\n",
        "    min_val = 10 ** (k - 1)\n",
        "    max_val = 10 ** k - 1\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        a = random.randint(min_val, max_val)\n",
        "        b = random.randint(min_val, max_val)\n",
        "        c = a + b\n",
        "        input_str = f\"0{a} + 0{b} =\"\n",
        "        output_str = str(c)\n",
        "        data.append((input_str, output_str))\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "agAsbFM8fHqr"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k3_data = generate_length_generalization_data(k=3, num_samples=700)\n",
        "print(k3_data[0])\n",
        "k3_dataset = AdditionDataset(k3_data, tokenizer, max_length=32)\n",
        "k3_loader = DataLoader(k3_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "k3_loss, k3_char_acc, k3_seq_acc = evaluate(\n",
        "    model, k3_loader, criterion, tokenizer, device\n",
        ")\n",
        "\n",
        "print(f\"\\n3-Digit Results:\")\n",
        "print(f\"  Loss: {k3_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {k3_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {k3_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, k3_dataset, tokenizer, device, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_1Hkdnuf89l",
        "outputId": "b592564f-27bd-4d7b-fbca-4302c87ff4b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('320 + 734 =', '1054')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 6/6 [00:00<00:00, 31.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3-Digit Results:\n",
            "  Loss: 8.3568\n",
            "  Character Accuracy: 0.3783\n",
            "  Sequence Accuracy: 0.0057\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     279 + 680 =\n",
            "Expected:    959\n",
            "Target:      959\n",
            "Predicted:   599\n",
            "Problem:     336 + 252 =\n",
            "Expected:    588\n",
            "Target:      588\n",
            "Predicted:   888\n",
            "Problem:     940 + 659 =\n",
            "Expected:    1599\n",
            "Target:      1599\n",
            "Predicted:   5999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem:     170 + 250 =\n",
            "Expected:    420\n",
            "Target:      420\n",
            "Predicted:   200\n",
            "Problem:     716 + 398 =\n",
            "Expected:    1114\n",
            "Target:      1114\n",
            "Predicted:   1444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_hard_carry_data(num_samples=1000):\n",
        "    \"\"\"Generate additions with many 9s (difficult carries)\"\"\"\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Generate numbers with high probability of 9s\n",
        "        a_digits = [random.choice([9, 9, 9, random.randint(0, 9)]) for _ in range(4)]\n",
        "        b_digits = [random.choice([9, 9, 9, random.randint(0, 9)]) for _ in range(4)]\n",
        "\n",
        "        a = int(''.join(map(str, a_digits)))\n",
        "        b = int(''.join(map(str, b_digits)))\n",
        "\n",
        "        # Ensure 4 digits\n",
        "        if a < 1000:\n",
        "            a += 1000\n",
        "        if b < 1000:\n",
        "            b += 1000\n",
        "\n",
        "        c = a + b\n",
        "        input_str = f\"{a} + {b} =\"\n",
        "        output_str = str(c)\n",
        "        data.append((input_str, output_str))\n",
        "\n",
        "    return data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DISTRIBUTION SHIFT: MANY 9s (HARD CARRIES)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "hard_carry_data = generate_hard_carry_data(num_samples=1000)\n",
        "hard_carry_dataset = AdditionDataset(hard_carry_data, tokenizer, max_length=32)\n",
        "hard_carry_loader = DataLoader(hard_carry_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "hc_loss, hc_char_acc, hc_seq_acc = evaluate(\n",
        "    model, hard_carry_loader, criterion, tokenizer, device\n",
        ")\n",
        "\n",
        "print(f\"\\nHard Carry Results:\")\n",
        "print(f\"  Loss: {hc_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {hc_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {hc_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, hard_carry_dataset, tokenizer, device, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCVcqmtFwyP7",
        "outputId": "6b6aafd3-379f-43e9-97be-705622faaa04"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DISTRIBUTION SHIFT: MANY 9s (HARD CARRIES)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 30.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hard Carry Results:\n",
            "  Loss: 0.0000\n",
            "  Character Accuracy: 1.0000\n",
            "  Sequence Accuracy: 1.0000\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     9949 + 9999 =\n",
            "Expected:    19948\n",
            "Target:      19948\n",
            "Predicted:   19948\n",
            "Problem:     9999 + 9598 =\n",
            "Expected:    19597\n",
            "Target:      19597\n",
            "Predicted:   19597\n",
            "Problem:     9199 + 9999 =\n",
            "Expected:    19198\n",
            "Target:      19198\n",
            "Predicted:   19198\n",
            "Problem:     9997 + 6935 =\n",
            "Expected:    16932\n",
            "Target:      16932\n",
            "Predicted:   16932\n",
            "Problem:     9998 + 9395 =\n",
            "Expected:    19393\n",
            "Target:      19393\n",
            "Predicted:   19393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_small_numbers_data(num_samples=1000):\n",
        "    \"\"\"Generate additions with small numbers (1000-3000)\"\"\"\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        a = random.randint(1000, 3000)\n",
        "        b = random.randint(1000, 3000)\n",
        "        c = a + b\n",
        "        input_str = f\"{a} + {b} =\"\n",
        "        output_str = str(c)\n",
        "        data.append((input_str, output_str))\n",
        "\n",
        "    return data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DISTRIBUTION SHIFT: SMALL NUMBERS ONLY (1000-3000)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "small_data = generate_small_numbers_data(num_samples=1000)\n",
        "small_dataset = AdditionDataset(small_data, tokenizer, max_length=32)\n",
        "small_loader = DataLoader(small_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "small_loss, small_char_acc, small_seq_acc = evaluate(\n",
        "    model, small_loader, criterion, tokenizer, device\n",
        ")\n",
        "\n",
        "print(f\"\\nSmall Numbers Results:\")\n",
        "print(f\"  Loss: {small_loss:.4f}\")\n",
        "print(f\"  Character Accuracy: {small_char_acc:.4f}\")\n",
        "print(f\"  Sequence Accuracy: {small_seq_acc:.4f}\")\n",
        "\n",
        "print_sample_predictions(model, small_dataset, tokenizer, device, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMdTzfPE6gY5",
        "outputId": "387557f7-7ebd-4958-ecfa-7c045bda3abe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DISTRIBUTION SHIFT: SMALL NUMBERS ONLY (1000-3000)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 28.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Small Numbers Results:\n",
            "  Loss: 0.0000\n",
            "  Character Accuracy: 1.0000\n",
            "  Sequence Accuracy: 1.0000\n",
            "SAMPLE PREDICTIONS\n",
            "Problem:     1982 + 1824 =\n",
            "Expected:    3806\n",
            "Target:      3806\n",
            "Predicted:   3806\n",
            "Problem:     2739 + 1159 =\n",
            "Expected:    3898\n",
            "Target:      3898\n",
            "Predicted:   3898\n",
            "Problem:     1642 + 1540 =\n",
            "Expected:    3182\n",
            "Target:      3182\n",
            "Predicted:   3182\n",
            "Problem:     2786 + 1698 =\n",
            "Expected:    4484\n",
            "Target:      4484\n",
            "Predicted:   4484\n",
            "Problem:     1731 + 1423 =\n",
            "Expected:    3154\n",
            "Target:      3154\n",
            "Predicted:   3154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-593kKed6mvv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}